{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 樸素貝葉斯分類器 (Naive Bayes Classifier)\n",
    "\n",
    "樸素貝葉斯是基於貝葉斯定理的概率分類算法，假設特徵之間相互獨立。\n",
    "\n",
    "## 貝葉斯定理\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "在分類問題中：\n",
    "P(類別|特徵) = P(特徵|類別) * P(類別) / P(特徵)\n",
    "\n",
    "## sklearn 中的樸素貝葉斯變體\n",
    "- **GaussianNB**: 適用於連續特徵，假設特徵服從高斯分布\n",
    "- **MultinomialNB**: 適用於離散特徵，常用於文本分類\n",
    "- **BernoulliNB**: 適用於二元特徵\n",
    "- **ComplementNB**: 適用於不平衡資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 1: 使用 GaussianNB 處理 Iris 資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Iris 資料集\n",
    "iris = datasets.load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "print(f\"特徵名稱: {iris.feature_names}\")\n",
    "print(f\"類別名稱: {iris.target_names}\")\n",
    "print(f\"資料形狀: {X_iris.shape}\")\n",
    "print(f\"類別分布: {np.bincount(y_iris)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42, stratify=y_iris\n",
    ")\n",
    "\n",
    "print(f\"訓練集大小: {X_train.shape}\")\n",
    "print(f\"測試集大小: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立並訓練 GaussianNB 模型\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = gnb.predict(X_test)\n",
    "y_pred_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "# 評估結果\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"準確率: {accuracy:.4f}\")\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩陣視覺化\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, \n",
    "            yticklabels=iris.target_names)\n",
    "plt.title('Iris 資料集 - GaussianNB 混淆矩陣')\n",
    "plt.xlabel('預測類別')\n",
    "plt.ylabel('實際類別')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 2: 使用 MultinomialNB 處理文本分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 載入新聞群組資料 (部分類別)\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, \n",
    "                                     shuffle=True, random_state=42)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, \n",
    "                                    shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"訓練文檔數量: {len(newsgroups_train.data)}\")\n",
    "print(f\"測試文檔數量: {len(newsgroups_test.data)}\")\n",
    "print(f\"類別: {newsgroups_train.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本向量化\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_text = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test_text = vectorizer.transform(newsgroups_test.data)\n",
    "y_train_text = newsgroups_train.target\n",
    "y_test_text = newsgroups_test.target\n",
    "\n",
    "print(f\"特徵向量形狀: {X_train_text.shape}\")\n",
    "print(f\"詞彙量: {len(vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 MultinomialNB 進行文本分類\n",
    "mnb = MultinomialNB(alpha=1.0)  # alpha 是平滑參數\n",
    "mnb.fit(X_train_text, y_train_text)\n",
    "\n",
    "# 預測\n",
    "y_pred_text = mnb.predict(X_test_text)\n",
    "\n",
    "# 評估\n",
    "accuracy_text = accuracy_score(y_test_text, y_pred_text)\n",
    "print(f\"文本分類準確率: {accuracy_text:.4f}\")\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_test_text, y_pred_text, \n",
    "                          target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 3: 使用 BernoulliNB 處理二元特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入乳癌資料集\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer.data, cancer.target\n",
    "\n",
    "# 將連續特徵二值化 (大於中位數為1，否則為0)\n",
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=np.median(X_cancer, axis=0))\n",
    "X_cancer_binary = binarizer.fit_transform(X_cancer)\n",
    "\n",
    "print(f\"原始特徵形狀: {X_cancer.shape}\")\n",
    "print(f\"二值化後特徵形狀: {X_cancer_binary.shape}\")\n",
    "print(f\"類別分布: {np.bincount(y_cancer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割資料\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(\n",
    "    X_cancer_binary, y_cancer, test_size=0.3, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# 使用 BernoulliNB\n",
    "bnb = BernoulliNB(alpha=1.0)\n",
    "bnb.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# 預測\n",
    "y_pred_binary = bnb.predict(X_test_binary)\n",
    "\n",
    "# 評估\n",
    "accuracy_binary = accuracy_score(y_test_binary, y_pred_binary)\n",
    "print(f\"BernoulliNB 準確率: {accuracy_binary:.4f}\")\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary, \n",
    "                          target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 4: 比較不同樸素貝葉斯算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Wine 資料集比較不同算法\n",
    "wine = datasets.load_wine()\n",
    "X_wine, y_wine = wine.data, wine.target\n",
    "\n",
    "# 分割資料\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.3, random_state=42, stratify=y_wine\n",
    ")\n",
    "\n",
    "# 標準化 (對 GaussianNB 有益)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_wine)\n",
    "X_test_scaled = scaler.transform(X_test_wine)\n",
    "\n",
    "# 二值化 (對 BernoulliNB)\n",
    "binarizer_wine = Binarizer(threshold=0)  # 標準化後以0為閾值\n",
    "X_train_wine_binary = binarizer_wine.fit_transform(X_train_scaled)\n",
    "X_test_wine_binary = binarizer_wine.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Wine 資料集特徵數: {X_wine.shape[1]}\")\n",
    "print(f\"類別數: {len(wine.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較不同算法\n",
    "models = {\n",
    "    'GaussianNB': (GaussianNB(), X_train_scaled, X_test_scaled),\n",
    "    'MultinomialNB': (MultinomialNB(), X_train_wine, X_test_wine),  # 需要非負值\n",
    "    'BernoulliNB': (BernoulliNB(), X_train_wine_binary, X_test_wine_binary)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (model, X_tr, X_te) in models.items():\n",
    "    try:\n",
    "        # 訓練模型\n",
    "        model.fit(X_tr, y_train_wine)\n",
    "        \n",
    "        # 預測\n",
    "        y_pred = model.predict(X_te)\n",
    "        \n",
    "        # 交叉驗證\n",
    "        cv_scores = cross_val_score(model, X_tr, y_train_wine, cv=5)\n",
    "        \n",
    "        # 儲存結果\n",
    "        results[name] = {\n",
    "            'test_accuracy': accuracy_score(y_test_wine, y_pred),\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  測試準確率: {results[name]['test_accuracy']:.4f}\")\n",
    "        print(f\"  交叉驗證: {results[name]['cv_mean']:.4f} (+/- {results[name]['cv_std']*2:.4f})\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{name} 執行錯誤: {e}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 5: 超參數調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 對 GaussianNB 調整平滑參數 (var_smoothing)\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "gnb_grid = GridSearchCV(\n",
    "    GaussianNB(), param_grid, cv=5, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "gnb_grid.fit(X_train_scaled, y_train_wine)\n",
    "\n",
    "print(f\"最佳參數: {gnb_grid.best_params_}\")\n",
    "print(f\"最佳交叉驗證分數: {gnb_grid.best_score_:.4f}\")\n",
    "\n",
    "# 測試最佳模型\n",
    "best_gnb = gnb_grid.best_estimator_\n",
    "y_pred_best = best_gnb.predict(X_test_scaled)\n",
    "print(f\"測試集準確率: {accuracy_score(y_test_wine, y_pred_best):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 6: 特徵重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用文本分類的特徵重要性\n",
    "# 取得每個類別的特徵對數概率\n",
    "feature_log_prob = mnb.feature_log_prob_\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 找出每個類別最重要的詞彙\n",
    "n_top_words = 10\n",
    "\n",
    "for i, category in enumerate(newsgroups_train.target_names):\n",
    "    top_indices = np.argsort(feature_log_prob[i])[-n_top_words:]\n",
    "    top_words = [feature_names[idx] for idx in reversed(top_indices)]\n",
    "    print(f\"\\n{category} 類別最重要的詞彙:\")\n",
    "    print(\", \".join(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "### 樸素貝葉斯的優點：\n",
    "- 訓練速度快，預測效率高\n",
    "- 對小樣本表現良好\n",
    "- 對不相關特徵不敏感\n",
    "- 可以處理多分類問題\n",
    "- 提供概率預測\n",
    "\n",
    "### 樸素貝葉斯的缺點：\n",
    "- 假設特徵獨立（現實中很少成立）\n",
    "- 對特徵分布假設敏感\n",
    "- 需要平滑處理零概率問題\n",
    "\n",
    "### 選擇指南：\n",
    "- **GaussianNB**: 連續特徵，假設高斯分布\n",
    "- **MultinomialNB**: 計數特徵，如詞頻\n",
    "- **BernoulliNB**: 二元特徵\n",
    "- **ComplementNB**: 不平衡資料集"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}